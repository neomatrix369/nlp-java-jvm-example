{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.version: 9.0.4\n"
     ]
    }
   ],
   "source": [
    "System.out.println(\"java.version: \" + System.getProperty(\"java.version\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.specification.version: 9\n",
      "java.runtime.version: 9.0.4+11\n"
     ]
    }
   ],
   "source": [
    "System.out.println(\"java.specification.version: \" + System.getProperty(\"java.specification.version\"));\n",
    "System.out.println(\"java.runtime.version: \" + System.getProperty(\"java.runtime.version\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java runtime VM version: 9.0.4+11\n"
     ]
    }
   ],
   "source": [
    "import java.lang.management.ManagementFactory;\n",
    "\n",
    "System.out.println(\"java runtime VM version: \" + ManagementFactory.getRuntimeMXBean().getVmVersion());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Apache OpenNLP jar files located in the ../shared/apache-opennlp-1.9.1/lib/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "List<String> addedJars = %jars \"../shared/apache-opennlp-1.9.1/lib/*.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[/home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jackson-annotations-2.8.4.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/morfologik-stemming-2.1.3.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/grizzly-http-server-2.3.28.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-common-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/morfologik-fsa-2.1.3.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-media-jaxb-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-guava-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/hk2-api-2.5.0-b30.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/grizzly-http-2.3.28.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jackson-jaxrs-base-2.8.4.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/opennlp-morfologik-addon-1.9.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/validation-api-1.1.0.Final.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-server-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/grizzly-framework-2.3.28.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/javax.annotation-api-1.2.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/opennlp-brat-annotator-1.9.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/morfologik-tools-2.1.3.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/osgi-resource-locator-1.0.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/morfologik-fsa-builders-2.1.3.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/javassist-3.20.0-GA.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/hk2-utils-2.5.0-b30.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jackson-core-2.8.4.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jackson-databind-2.8.4.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/javax.inject-2.5.0-b30.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/opennlp-tools-1.9.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/hppc-0.7.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/opennlp-uima-1.9.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/hk2-locator-2.5.0-b30.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/javax.ws.rs-api-2.0.1.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-container-grizzly2-http-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-media-json-jackson-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jcommander-1.48.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/aopalliance-repackaged-2.5.0-b30.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-entity-filtering-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jersey-client-2.25.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jackson-jaxrs-json-provider-2.8.4.jar, /home/jovyan/work/./../shared/apache-opennlp-1.9.1/lib/jackson-module-jaxb-annotations-2.8.4.jar]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addedJars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to find out about each of the classes enlisted in this notebook please refer to the Java API JavaDocs at  https://opennlp.apache.org/docs/1.9.1/apidocs/opennlp-tools/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Detector API: \n",
    "##### Import the Language detecting model called langdetect-183.bin from the \"../shared/\" folder, and show a simple example detecting a language of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best language: lat\n",
      "Best language confidence: 0.017774467481479657\n",
      "\n",
      "Predict languages (with confidence): [tur (0.009708737864077673), bel (0.009708737864077673), san (0.009708737864077673), ara (0.009708737864077673), mon (0.009708737864077673), tel (0.009708737864077673), sin (0.009708737864077673), pes (0.009708737864077673), min (0.009708737864077673), cmn (0.009708737864077673), aze (0.009708737864077673), fao (0.009708737864077673), ita (0.009708737864077673), ceb (0.009708737864077673), mkd (0.009708737864077673), eng (0.009708737864077673), nno (0.009708737864077673), lvs (0.009708737864077673), kor (0.009708737864077673), som (0.009708737864077673), swa (0.009708737864077673), hun (0.009708737864077673), fra (0.009708737864077673), nld (0.009708737864077673), mlt (0.009708737864077673), bak (0.009708737864077673), ekk (0.009708737864077673), ron (0.009708737864077673), gle (0.009708737864077673), hin (0.009708737864077673), est (0.009708737864077673), tha (0.009708737864077673), slk (0.009708737864077673), ltz (0.009708737864077673), kan (0.009708737864077673), eus (0.009708737864077673), epo (0.009708737864077673), bos (0.009708737864077673), pol (0.009708737864077673), nep (0.009708737864077673), lit (0.009708737864077673), war (0.009708737864077673), srp (0.009708737864077673), ces (0.009708737864077673), che (0.009708737864077673), lav (0.009708737864077673), nds (0.009708737864077673), dan (0.009708737864077673), mar (0.009708737864077673), nan (0.009708737864077673), glg (0.009708737864077673), gsw (0.009708737864077673), fry (0.009708737864077673), uzb (0.009708737864077673), mal (0.009708737864077673), vol (0.009708737864077673), fas (0.009708737864077673), msa (0.009708737864077673), cym (0.009708737864077673), nob (0.009708737864077673), ben (0.009708737864077673), kaz (0.009708737864077673), heb (0.009708737864077673), bre (0.009708737864077673), jav (0.009708737864077673), sqi (0.009708737864077673), kir (0.009708737864077673), cat (0.009708737864077673), oci (0.009708737864077673), vie (0.009708737864077673), kat (0.009708737864077673), tam (0.009708737864077673), tgk (0.009708737864077673), mri (0.009708737864077673), slv (0.009708737864077673), lat (0.009708737864077673), tgl (0.009708737864077673), pan (0.009708737864077673), swe (0.009708737864077673), lim (0.009708737864077673), tat (0.009708737864077673), ell (0.009708737864077673), afr (0.009708737864077673), pus (0.009708737864077673), isl (0.009708737864077673), sun (0.009708737864077673), urd (0.009708737864077673), hye (0.009708737864077673), hrv (0.009708737864077673), ast (0.009708737864077673), rus (0.009708737864077673), spa (0.009708737864077673), ind (0.009708737864077673), pnb (0.009708737864077673), bul (0.009708737864077673), plt (0.009708737864077673), deu (0.009708737864077673), zul (0.009708737864077673), ukr (0.009708737864077673), jpn (0.009708737864077673), por (0.009708737864077673), guj (0.009708737864077673), fin (0.009708737864077673)]\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.langdetect.LanguageDetectorModel;\n",
    "import opennlp.tools.langdetect.LanguageDetectorME;\n",
    "import opennlp.tools.langdetect.LanguageDetector;\n",
    "import opennlp.tools.langdetect.Language;\n",
    "\n",
    "try (InputStream modelIn = new FileInputStream(\"../shared/langdetect-183.bin\")) {\n",
    "    LanguageDetectorModel langModel = new LanguageDetectorModel(modelIn);\n",
    "    String inputText = \"This is a sample text.\";\n",
    "\n",
    "    // Get the most probable language\n",
    "    LanguageDetector myCategorizer = new LanguageDetectorME(langModel);\n",
    "    Language bestLanguage = myCategorizer.predictLanguage(inputText);\n",
    "    System.out.println(\"Best language: \" + bestLanguage.getLang());\n",
    "    System.out.println(\"Best language confidence: \" + bestLanguage.getConfidence());\n",
    "\n",
    "    // Get an array with the most probable languages\n",
    "    Language[] languages = myCategorizer.predictLanguages(\"\");\n",
    "    System.out.println(\"\");\n",
    "    System.out.println(\"Predict languages (with confidence): \" + Arrays.toString(languages));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apparantly it detects this to be Latin, instead of English \n",
    "maybe the language detecting model needs more training.\n",
    "See https://opennlp.apache.org/docs/1.9.1/manual/opennlp.html#tools.langdetect.training on how this can be achieved**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Detection API\n",
    "##### Import the [en] Sentence detecting model called en-sent.bin from the \"../shared/\" folder, and show a simple example detecting a language of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[First sentence., Second sentence.]\n",
      "\n",
      "[[2..17), [18..34)]\n"
     ]
    }
   ],
   "source": [
    "import opennlp.tools.sentdetect.SentenceModel;\n",
    "import opennlp.tools.sentdetect.SentenceDetectorME;\n",
    "import opennlp.tools.util.Span;\n",
    "\n",
    "try (InputStream modelIn = new FileInputStream(\"../shared/en-sent.bin\")) {\n",
    "  SentenceModel model = new SentenceModel(modelIn);\n",
    "  SentenceDetectorME sentenceDetector = new SentenceDetectorME(model);\n",
    "  String sentences[] = sentenceDetector.sentDetect(\"  First sentence. Second sentence. \");\n",
    "  System.out.println(Arrays.toString(sentences));\n",
    "  Span sentencesUsingSpan[] = sentenceDetector.sentPosDetect(\"  First sentence. Second sentence. \");\n",
    "  System.out.println();\n",
    "  System.out.println(Arrays.toString(sentencesUsingSpan));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see the two ways to use the SentenceDetect API to detect sentences in a piece of text.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer API\n",
    "##### Load the [en] Tokenizer model called en-token.bin from the ../shared folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompilationException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    \u001b[0m\u001b[1m\u001b[30m\u001b[41mtokensProbabilies.stream\u001b[0m\u001b[1m\u001b[30m.map(tp -> System.print(tp) + \", \").toCollect();\u001b[0m",
      "\u001b[1m\u001b[31mcannot find symbol\u001b[0m",
      "\u001b[1m\u001b[31m  symbol:   variable stream\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "import opennlp.tools.tokenize.TokenizerModel;\n",
    "import opennlp.tools.tokenize.TokenizerME;\n",
    "import opennlp.tools.tokenize.Tokenizer;\n",
    "import opennlp.tools.util.Span;\n",
    "\n",
    "try(InputStream modelIn = new FileInputStream(\"../shared/en-token.bin\")) {\n",
    "    TokenizerModel model = new TokenizerModel(modelIn);\n",
    "    TokenizerME tokenizer = new TokenizerME(model);\n",
    "    String tokens[] = tokenizer.tokenize(\"An input sample sentence.\");\n",
    "    System.out.println(Arrays.toString(tokens));\n",
    "    double tokensProbabilies[] = tokenizer.getTokenProbabilities();\n",
    "    tokensProbabilies.stream.map(tp -> System.print(tp) + \", \").toCollect();\n",
    "    System.out.println();\n",
    "    Span tokensUsingSpans[] = tokenizer.tokenizePos(\"An input sample sentence.\");\n",
    "    System.out.println(Arrays.toString(tokensUsingSpans));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "9.0.4+11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
